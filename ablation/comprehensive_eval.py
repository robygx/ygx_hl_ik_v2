#!/usr/bin/env python3
"""
PiM-IK 综合评估脚本 (遵循全局评估标准)
==========================================

评估指标:
1. Params (K): 参数量
2. Latency (ms): 推理延迟
3. Swivel MAE (°): 臂角绝对误差
4. Elbow Error (mm): 肘部空间误差
5. Jerk: 动作平滑度惩罚
6. Joint MAE (°): 端到端关节角度误差

使用方法:
    python ablation/comprehensive_eval.py --experiment loss_ablation
    python ablation/comprehensive_eval.py --experiment window_size_ablation
    python ablation/comprehensive_eval.py --experiment backbone_ablation
    python ablation/comprehensive_eval.py --experiment layers_ablation
"""

import os
import sys

# ============================================================================
# 修复 GLIBC 版本问题：使用 ctypes 预加载正确版本的 libstdc++
# ============================================================================
import ctypes
import ctypes.util

# 首先尝试预加载 conda 环境的 libstdc++
conda_env_lib = os.path.expanduser('~/.conda/envs/tv/lib')
if os.path.exists(conda_env_lib):
    libstdcxx_path = os.path.join(conda_env_lib, 'libstdc++.so.6')
    if os.path.exists(libstdcxx_path):
        try:
            # 预加载新版本的 libstdc++（RTLD_GLOBAL 让后续模块也使用它）
            ctypes.CDLL(libstdcxx_path, mode=ctypes.RTLD_GLOBAL)
            print(f"[Info] 已预加载 conda 环境的 libstdc++ (GLIBCXX_3.4.31)")
        except Exception as e:
            print(f"[Warning] 无法预加载 libstdc++: {e}")

    # 设置环境变量
    os.environ['LD_LIBRARY_PATH'] = conda_env_lib + ':' + os.environ.get('LD_LIBRARY_PATH', '')

import argparse
import numpy as np
import torch
import torch.nn as nn
from pathlib import Path
from typing import Dict, Optional, Tuple
import json
import time

# 用于传统 IK 求解器
try:
    from scipy.optimize import minimize
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False
    print("[Warning] scipy 不可用，传统 IK 求解器将无法使用")

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT.parent))

from core.pim_ik_net import PiM_IK_Net

# ============================================================================
# 真实 IK 求解器 (可选导入)
# ============================================================================

REAL_IK_AVAILABLE = False
HierarchicalIKSolver = None
G1_29_ArmIK = None

try:
    # 修复 GLIBC 版本问题：设置 LD_LIBRARY_PATH 优先使用 conda 环境的 libstdc++
    conda_env_path = os.path.expanduser('~/.conda/envs/tv/lib')
    if os.path.exists(conda_env_path):
        os.environ['LD_LIBRARY_PATH'] = conda_env_path + ':' + os.environ.get('LD_LIBRARY_PATH', '')

    # 尝试导入 hl_ik_xr_tele 中的 IK 求解器
    hl_ik_xr_tele_path = '/home/ygx/hl_ik_xr_tele'
    if hl_ik_xr_tele_path not in sys.path:
        sys.path.insert(0, hl_ik_xr_tele_path)

    from teleop.robot_control.robot_arm_ik_nn_ygx import (
        G1_29_ArmIK, HierarchicalIKSolver
    )
    REAL_IK_AVAILABLE = True
    print("[Info] 真实 IK 求解器可用 (G1_29_ArmIK)")
except ImportError as e:
    print(f"[Warning] 无法导入真实 IK 求解器: {e}")
    print("[Info] 将使用近似方法 (elbow_error / 3) 计算 Joint MAE")


# ============================================================================
# TargetGenerator (内联实现，避免导入问题)
# ============================================================================

class TargetGenerator:
    """
    Neural-to-Physics 桥梁：将网络预测的臂角转换为肘部 3D 坐标

    算法原理：
        基于轨道圆几何逻辑，使用纯 numpy 实现将 [cos(φ), sin(φ)] 转换为肘部坐标。
    """

    EPS = 1e-6  # 数值稳定性常数

    # 避奇异参考向量（指向胸腔正后方）
    V_REF = np.array([-1.0, 0.0, 0.0])
    V_REF_ALT = np.array([0.0, 1.0, 0.0])

    def __init__(self):
        """初始化目标生成器"""
        pass

    def compute_target_elbow_position(
        self,
        swivel_angle: np.ndarray,
        p_s: np.ndarray,
        p_w: np.ndarray,
        L_upper: float,
        L_lower: float
    ) -> np.ndarray:
        """
        计算目标肘部位置

        Args:
            swivel_angle: (2,) 预测的臂角 [cos(φ), sin(φ)]
            p_s: (3,) 肩部 3D 坐标
            p_w: (3,) 腕部 3D 坐标
            L_upper: 上臂长度
            L_lower: 前臂长度

        Returns:
            p_e_target: (3,) 目标肘部 3D 坐标
        """
        # L2 归一化预测臂角
        cos_phi, sin_phi = swivel_angle
        norm = np.sqrt(cos_phi**2 + sin_phi**2) + self.EPS
        cos_phi, sin_phi = cos_phi / norm, sin_phi / norm

        # 构建轨道圆坐标系的正交基 (u, v, n)
        sw = p_w - p_s
        sw_norm = np.linalg.norm(sw) + self.EPS

        # 主轴 n = sw / ||sw||
        n = sw / sw_norm

        # Gram-Schmidt 正交化构建 X 轴 u
        v_ref_dot_n = np.dot(self.V_REF, n)
        u_candidate = self.V_REF - v_ref_dot_n * n
        u_norm = np.linalg.norm(u_candidate)

        # 奇异点回退：当 u_norm < 1e-5 时切换到备用向量
        if u_norm < 1e-5:
            v_ref_alt_dot_n = np.dot(self.V_REF_ALT, n)
            u_candidate = self.V_REF_ALT - v_ref_alt_dot_n * n
            u_norm = np.linalg.norm(u_candidate) + self.EPS

        u = u_candidate / (u_norm + self.EPS)

        # 计算 Y 轴 v = n × u（叉积构建正交右手系）
        v = np.cross(n, u)

        # 利用余弦定理计算轨道圆参数
        L_upper_sq = L_upper ** 2
        L_lower_sq = L_lower ** 2
        sw_norm_sq = sw_norm ** 2

        d = (L_upper_sq - L_lower_sq + sw_norm_sq) / (2.0 * sw_norm + self.EPS)

        # 轨道圆心 p_c = p_s + d * n
        p_c = p_s + d * n

        # 轨道圆半径 R = sqrt(max(L_upper² - d², EPS))
        R_sq = max(L_upper_sq - d**2, self.EPS)
        R = np.sqrt(R_sq)

        # 计算预测肘部位置
        offset = R * (cos_phi * u + sin_phi * v)
        p_e_target = p_c + offset

        return p_e_target


# ============================================================================
# 模型加载
# ============================================================================

def load_model(checkpoint_path: str, device: str = 'cuda:0') -> Tuple[nn.Module, Dict]:
    """加载模型并返回模型和配置信息"""
    import re

    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"模型文件不存在: {checkpoint_path}")

    print(f"[Model] 加载模型: {checkpoint_path}")

    # 根据路径识别骨干类型
    backbone_type = 'mamba'  # 默认
    if '/lstm/' in checkpoint_path or '_lstm_' in checkpoint_path:
        backbone_type = 'lstm'
    elif '/transformer/' in checkpoint_path or '_transformer_' in checkpoint_path:
        backbone_type = 'transformer'

    # 根据路径识别层数
    num_layers = 4  # 默认
    # 匹配 L2, L4, L6, L8 等模式
    layer_match = re.search(r'_L(\d+)_', checkpoint_path)
    if layer_match:
        num_layers = int(layer_match.group(1))
    # 匹配 layers2, layers4 等模式
    elif 'layers' in checkpoint_path:
        layers_match = re.search(r'layers(\d+)', checkpoint_path)
        if layers_match:
            num_layers = int(layers_match.group(1))

    print(f"[Model] 骨干类型: {backbone_type}, 层数: {num_layers}")

    # 创建模型
    model = PiM_IK_Net(d_model=256, num_layers=num_layers, backbone_type=backbone_type).to(device)

    # 加载权重
    checkpoint = torch.load(checkpoint_path, map_location=device)

    # 处理 DDP 权重
    if 'model_state_dict' in checkpoint:
        state_dict = checkpoint['model_state_dict']
        new_state_dict = {}
        for k, v in state_dict.items():
            if k.startswith('module.'):
                new_state_dict[k[7:]] = v
            else:
                new_state_dict[k] = v
        model.load_state_dict(new_state_dict)

        # 提取配置信息
        config = {
            'window_size': checkpoint.get('window_size', 30),
            'epoch': checkpoint.get('epoch', -1),
            'val_loss': checkpoint.get('val_loss', -1),
            'loss_weights': checkpoint.get('loss_weights', {})
        }
    else:
        model.load_state_dict(checkpoint)
        config = {}

    model.eval()
    return model, config


def count_parameters(model: nn.Module) -> int:
    """统计模型参数量"""
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


# ============================================================================
# 推理延迟测试
# ============================================================================

def measure_inference_latency(
    model: nn.Module,
    T_ee_sample: np.ndarray,
    window_size: int,
    device: str,
    warmup: int = 100,
    num_runs: int = 1000
) -> Dict:
    """
    测量推理延迟

    遵循标准:
    - 使用 torch.cuda.synchronize() 确保准确计时
    - 进行充分预热 (warmup)
    - 多次运行取平均
    """
    model.eval()

    # 构建窗口输入
    T_ee_window = np.repeat(T_ee_sample[np.newaxis, :, :], window_size, axis=0)  # (W, 4, 4)

    # 转换为 tensor
    T_ee_tensor = torch.from_numpy(T_ee_window.astype(np.float32)).unsqueeze(0).to(device)

    # 预热
    with torch.no_grad():
        for _ in range(warmup):
            _ = model(T_ee_tensor)

    if device.startswith('cuda'):
        torch.cuda.synchronize()

    # 计时
    latencies = []
    with torch.no_grad():
        for _ in range(num_runs):
            start = time.perf_counter()
            _ = model(T_ee_tensor)
            if device.startswith('cuda'):
                torch.cuda.synchronize()
            end = time.perf_counter()
            latencies.append((end - start) * 1000)  # 转换为毫秒

    return {
        'mean': np.mean(latencies),
        'std': np.std(latencies),
        'min': np.min(latencies),
        'max': np.max(latencies),
        'p50': np.percentile(latencies, 50),
        'p95': np.percentile(latencies, 95),
        'p99': np.percentile(latencies, 99),
    }


# ============================================================================
# 数据加载
# ============================================================================

def load_validation_data(npz_path: str, train_split: float = 0.95, num_frames: int = None) -> Dict:
    """加载验证集数据"""
    print(f"[Data] 加载数据: {npz_path}")

    raw = np.load(npz_path, allow_pickle=True)

    total_frames = len(raw['T_ee'])
    val_start = int(total_frames * train_split)

    # 限制帧数
    if num_frames:
        val_end = min(val_start + num_frames, total_frames)
    else:
        val_end = total_frames

    print(f"[Data] 评估帧数: {val_end - val_start:,}")

    data = {
        'T_ee': raw['T_ee'][val_start:val_end].astype(np.float32),
        'swivel': raw['swivel_angle'][val_start:val_end].astype(np.float32),
        'joint_pos': raw['joint_positions'][val_start:val_end].astype(np.float32),
        'L_upper': raw['L_upper'][val_start:val_end].astype(np.float32),
        'L_lower': raw['L_lower'][val_start:val_end].astype(np.float32),
        'is_valid': raw['is_valid'][val_start:val_end].astype(np.float32),
    }

    # 提取各关节坐标
    data['p_s'] = data['joint_pos'][:, 0, :]
    data['p_e_gt'] = data['joint_pos'][:, 1, :]
    data['p_w'] = data['joint_pos'][:, 2, :]

    # 提取 GT 关节角度 (y_original[:, 7:14] - 7 DOF)
    if 'y_original' in raw:
        # GT 关节角度在第 7-13 列（7个关节）
        # 注意: 21:28 是 IK 计算的关节角度，不是 GT
        data['gt_joints'] = raw['y_original'][val_start:val_end, 7:14].astype(np.float32)
        print(f"[Data] GT 关节角度已加载: {data['gt_joints'].shape}")
    else:
        data['gt_joints'] = None
        print("[Warning] 数据集中没有 y_original，无法计算 Joint MAE")

    return data


# ============================================================================
# 推理
# ============================================================================

def run_inference(model: nn.Module, T_ee: np.ndarray, window_size: int, device: str) -> np.ndarray:
    """运行滑动窗口推理"""
    model.eval()
    N = len(T_ee)
    W = window_size

    print(f"[Infer] 滑动窗口推理 (N={N}, W={W})...")

    pred_list = []
    warmup = W - 1

    with torch.no_grad():
        for i in range(warmup, N):
            # 构建窗口
            start_idx = i - warmup
            window = T_ee[start_idx:i + 1]

            # 前向传播
            window_tensor = torch.from_numpy(window).unsqueeze(0).to(device)
            pred = model(window_tensor)

            # 取最后一帧
            pred_last = pred[0, -1].cpu().numpy()
            pred_list.append(pred_last)

            # 进度
            if len(pred_list) % 10000 == 0:
                print(f"  已处理: {len(pred_list):,}/{N - warmup:,}")

    print(f"[Infer] 完成，输出 {len(pred_list):,} 帧")
    return np.array(pred_list)


# ============================================================================
# 指标计算 (遵循全局评估标准)
# ============================================================================

def compute_swivel_mae(pred: np.ndarray, gt: np.ndarray, is_valid: np.ndarray = None) -> float:
    """
    Metric 1: Swivel MAE (臂角绝对误差, 单位: Degree)

    物理意义：衡量网络对人类连续立体臂角意图的原始拟合精度

    代码要求：
    - 预测值为 [cos, sin]
    - 使用 np.arctan2 转换为角度
    - 严格处理 2π 周期性跳变
    - 最后转换为度数
    """
    pred_angle = np.arctan2(pred[:, 1], pred[:, 0])
    gt_angle = np.arctan2(gt[:, 1], gt[:, 0])

    diff = np.abs(pred_angle - gt_angle)
    diff = np.minimum(diff, 2 * np.pi - diff)  # 处理周期性

    if is_valid is not None:
        diff = diff[is_valid > 0.5]

    return np.degrees(diff).mean()


def compute_elbow_error(
    pred_swivel: np.ndarray,
    gt_swivel: np.ndarray,
    p_s: np.ndarray,
    p_w: np.ndarray,
    L_upper: np.ndarray,
    L_lower: np.ndarray,
    is_valid: np.ndarray = None
) -> float:
    """
    Metric 2: Elbow Error (肘部空间误差, 单位: mm)

    物理意义：衡量意图在三维物理空间中的拟人化精确度

    代码要求：
    - 通过 TargetGenerator 将预测臂角还原为 3D 肘部坐标
    - 与真实肘部坐标计算 L2 欧氏距离
    - 乘以 1000 转换为毫米
    """
    target_gen = TargetGenerator()

    errors = []
    for i in range(len(pred_swivel)):
        p_e_pred = target_gen.compute_target_elbow_position(
            pred_swivel[i], p_s[i], p_w[i], L_upper[i], L_lower[i]
        )
        p_e_gt = target_gen.compute_target_elbow_position(
            gt_swivel[i], p_s[i], p_w[i], L_upper[i], L_lower[i]
        )
        errors.append(np.linalg.norm(p_e_pred - p_e_gt) * 1000)

    errors = np.array(errors)

    if is_valid is not None:
        errors = errors[is_valid > 0.5]

    return errors.mean()


def compute_jerk(pred_swivel: np.ndarray, is_valid: np.ndarray = None) -> float:
    """
    Metric 3: Smoothness / Jerk (动作平滑度惩罚)

    物理意义：定量证明 Mamba 时序窗口带来的丝滑度

    代码要求：
    - 计算预测连续臂角时间序列的二阶差分均方值
    - 公式: 1/T * sum ||φ_t - 2φ_{t-1} + φ_{t-2}||²
    """
    # 转换为角度（度）
    phi = np.degrees(np.arctan2(pred_swivel[:, 1], pred_swivel[:, 0]))

    if is_valid is not None:
        valid_mask = is_valid > 0.5
        phi = phi[valid_mask]

    if len(phi) < 3:
        return 0.0

    # 二阶差分: φ_t - 2φ_{t-1} + φ_{t-2}
    jerk = phi[2:] - 2 * phi[1:-1] + phi[:-2]

    return np.mean(jerk ** 2)


# ============================================================================
# 误差时间序列关联分析
# ============================================================================

def analyze_error_correlation(
    pred_swivel: np.ndarray,
    gt_swivel: np.ndarray,
    gt_joints: np.ndarray,
    T_ee: np.ndarray,
    p_s: np.ndarray,
    p_w: np.ndarray,
    L_upper: np.ndarray,
    L_lower: np.ndarray,
    is_valid: np.ndarray,
    ik_solver,
    traditional_ik,
    output_dir: Path,
    model_name: str,
    sample_ratio: float = 0.1
) -> Dict:
    """
    分析臂角误差与关节角度误差的时间序列关联性

    目的：验证 VR 部署时机械臂抽动是否由臂角预测误差导致

    返回:
        - correlation: Pearson 相关系数
        - peak_sync_ratio: 峰值同步率
        - lag_correlation: 滞后相关系数
        - statistics: 统计信息
    """
    import matplotlib.pyplot as plt
    from scipy.stats import pearsonr
    from scipy.signal import find_peaks

    print(f"\n[Correlation] 开始分析臂角-关节误差关联性...")
    print(f"[Correlation] 模型: {model_name}, 采样比例: {sample_ratio*100:.0f}%")

    # 1. 计算每帧的 swivel_error 和 joint_error
    target_gen = TargetGenerator()
    N = len(pred_swivel)

    # 采样分析
    if sample_ratio < 1.0:
        sample_size = max(1000, int(N * sample_ratio))
        indices = np.linspace(0, N - 1, sample_size, dtype=int)
        print(f"[Correlation] 采样 {sample_size:,} 帧进行分析 (总共 {N:,} 帧)")
    else:
        indices = np.arange(N)
        print(f"[Correlation] 分析全部 {N:,} 帧")

    swivel_errors = []
    elbow_errors = []
    joint_errors = []
    frame_indices = []

    use_traditional_init = traditional_ik is not None and SCIPY_AVAILABLE

    for idx in indices:
        # 跳过无效帧
        if is_valid is not None and is_valid[idx] < 0.5:
            continue

        # 计算 swivel_error (角度差，度)
        pred_angle = np.arctan2(pred_swivel[idx, 1], pred_swivel[idx, 0])
        gt_angle = np.arctan2(gt_swivel[idx, 1], gt_swivel[idx, 0])
        diff = np.abs(pred_angle - gt_angle)
        diff = np.minimum(diff, 2 * np.pi - diff)
        swivel_err = np.degrees(diff)

        # 获取肘部位置
        p_e_pred = target_gen.compute_target_elbow_position(
            pred_swivel[idx], p_s[idx], p_w[idx], L_upper[idx], L_lower[idx]
        )
        # GT 肘部位置 (从 GT swivel 计算)
        p_e_gt = target_gen.compute_target_elbow_position(
            gt_swivel[idx], p_s[idx], p_w[idx], L_upper[idx], L_lower[idx]
        )
        # 计算肘部位置误差 (mm)
        elbow_err = np.linalg.norm(p_e_pred - p_e_gt) * 1000

        # IK 求解
        q_init_full = np.zeros(14, dtype=np.float32)
        if use_traditional_init and gt_joints is not None:
            q_init_14d = np.zeros(14, dtype=np.float32)
            q_init_14d[:7] = gt_joints[idx]
            q_traditional, _ = traditional_ik.solve(
                T_target=T_ee[idx], q_init=q_init_14d, max_iter=50, verbose=False
            )
            q_init_full[:7] = q_traditional[:7]
        elif gt_joints is not None:
            q_init_full[:7] = gt_joints[idx]

        q_solved, _ = ik_solver.solve(
            T_ee_target=T_ee[idx], p_e_target=p_e_pred,
            q_init=q_init_full, max_iter=50, verbose=False
        )

        # 计算 joint_error (度)
        if gt_joints is not None:
            joint_err = np.degrees(np.abs(q_solved[:7] - gt_joints[idx])).mean()
        else:
            joint_err = 0.0

        swivel_errors.append(swivel_err)
        elbow_errors.append(elbow_err)
        joint_errors.append(joint_err)
        frame_indices.append(idx)

    swivel_errors = np.array(swivel_errors)
    elbow_errors = np.array(elbow_errors)
    joint_errors = np.array(joint_errors)
    frame_indices = np.array(frame_indices)

    print(f"[Correlation] 有效帧数: {len(swivel_errors):,}")

    # 2. 计算统计指标
    # 2.1 swivel_error vs joint_error
    correlation, p_value = pearsonr(swivel_errors, joint_errors)

    # 2.2 swivel_error vs elbow_error (新增!)
    swivel_elbow_corr, swivel_elbow_p = pearsonr(swivel_errors, elbow_errors)

    # 2.3 elbow_error vs joint_error
    elbow_joint_corr, elbow_joint_p = pearsonr(elbow_errors, joint_errors)

    print(f"\n[Correlation] === 关联性分析结果 ===")
    print(f"[Correlation] swivel_error vs joint_error: r = {correlation:.3f} (p < {p_value:.3e})")
    print(f"[Correlation] swivel_error vs elbow_error: r = {swivel_elbow_corr:.3f} (p < {swivel_elbow_p:.3e})")
    print(f"[Correlation] elbow_error vs joint_error: r = {elbow_joint_corr:.3f} (p < {elbow_joint_p:.3e})")

    # 诊断 swivel → elbow 的转换
    if swivel_elbow_corr > 0.8:
        elbow_diagnosis = "✓ swivel→elbow 转换正常 (高相关)"
    elif swivel_elbow_corr > 0.5:
        elbow_diagnosis = "⚠ swivel→elbow 转换中等相关 (可能有参数问题)"
    else:
        elbow_diagnosis = "✗ swivel→elbow 转换异常 (低相关，检查 L_upper/L_lower)"
    print(f"[Correlation] {elbow_diagnosis}")

    # 峰值检测
    swivel_peaks, _ = find_peaks(swivel_errors, height=np.percentile(swivel_errors, 75))
    joint_peaks, _ = find_peaks(joint_errors, height=np.percentile(joint_errors, 75))

    # 峰值同步率
    peak_sync_count = 0
    for sp_idx in swivel_peaks:
        # 检查 joint_errors 在附近是否有峰值
        window = 10  # 10帧窗口
        for jp_idx in joint_peaks:
            if abs(frame_indices[sp_idx] - frame_indices[jp_idx]) <= window:
                peak_sync_count += 1
                break

    peak_sync_ratio = peak_sync_count / len(swivel_peaks) if len(swivel_peaks) > 0 else 0

    # 3. 滞后相关性分析
    max_lag = 30
    lag_correlations = []
    for lag in range(0, min(max_lag, len(swivel_errors) // 10)):
        if lag < len(joint_errors):
            lag_corr, _ = pearsonr(swivel_errors[:-lag or None], joint_errors[lag:])
            lag_correlations.append(lag_corr)
        else:
            lag_correlations.append(0.0)

    # 4. 可视化
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # 图1: 时间序列图 (双y轴)
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))

    # 上图: 完整时间序列
    color1 = 'tab:blue'
    ax1.set_xlabel('Frame Index')
    ax1.set_ylabel('Swivel Error (°)', color=color1)
    line1 = ax1.plot(frame_indices, swivel_errors, color=color1, alpha=0.7, label='Swivel Error')
    ax1.tick_params(axis='y', labelcolor=color1)

    ax1_r = ax1.twinx()
    color2 = 'tab:red'
    ax1_r.set_ylabel('Joint Error (°)', color=color2)
    line2 = ax1_r.plot(frame_indices, joint_errors, color=color2, alpha=0.7, label='Joint Error')
    ax1_r.tick_params(axis='y', labelcolor=color2)

    # 标记同步峰值
    sync_indices = []
    for sp_idx in swivel_peaks:
        for jp_idx in joint_peaks:
            if abs(frame_indices[sp_idx] - frame_indices[jp_idx]) <= 10:
                sync_indices.append((frame_indices[sp_idx], swivel_errors[sp_idx]))
                break

    if sync_indices:
        sync_x, sync_y = zip(*sync_indices)
        ax1.scatter(sync_x, sync_y, color='orange', s=50, zorder=5, marker='o', label='Synced Peaks')

    ax1.set_title(f'Error Time Series ({model_name})\nCorrelation: r={correlation:.3f}, p<{p_value:.3e}, Peak Sync: {peak_sync_ratio*100:.1f}%')
    ax1.grid(True, alpha=0.3)

    # 合并图例
    lines = line1 + line2
    labels = [l.get_label() for l in lines]
    ax1.legend(lines, labels, loc='upper left')

    # 下图: 局部放大 (前1000帧)
    max_show = min(1000, len(frame_indices))
    ax2.plot(frame_indices[:max_show], swivel_errors[:max_show], color=color1, alpha=0.7, label='Swivel Error')
    ax2_r = ax2.twinx()
    ax2_r.plot(frame_indices[:max_show], joint_errors[:max_show], color=color2, alpha=0.7, label='Joint Error')
    ax2.set_xlabel('Frame Index')
    ax2.set_ylabel('Swivel Error (°)', color=color1)
    ax2_r.set_ylabel('Joint Error (°)', color=color2)
    ax2.tick_params(axis='y', labelcolor=color1)
    ax2_r.tick_params(axis='y', labelcolor=color2)
    ax2.set_title('Zoomed View (First 1000 Frames)')
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()
    ts_path = output_dir / f'error_correlation_{model_name}.png'
    plt.savefig(ts_path, dpi=150)
    plt.close()
    print(f"[Correlation] 时间序列图已保存: {ts_path}")

    # 图2: 散点图 + 回归线
    fig, ax = plt.subplots(figsize=(10, 8))

    scatter = ax.scatter(swivel_errors, joint_errors, alpha=0.3, s=10, c=frame_indices, cmap='viridis')
    ax.set_xlabel('Swivel Error (°)')
    ax.set_ylabel('Joint Error (°)')
    ax.set_title(f'Error Correlation Scatter Plot ({model_name})')

    # 添加回归线
    from scipy.stats import linregress
    slope, intercept, r_value, p_value, std_err = linregress(swivel_errors, joint_errors)
    x_line = np.linspace(swivel_errors.min(), swivel_errors.max(), 100)
    y_line = slope * x_line + intercept
    ax.plot(x_line, y_line, 'r-', linewidth=2, label=f'y = {slope:.3f}x + {intercept:.3f}\nr = {r_value:.3f}')

    # 添加颜色条
    cbar = plt.colorbar(scatter, ax=ax)
    cbar.set_label('Frame Index')

    ax.legend()
    ax.grid(True, alpha=0.3)
    scatter_path = output_dir / f'error_scatter_{model_name}.png'
    plt.savefig(scatter_path, dpi=150)
    plt.close()
    print(f"[Correlation] 散点图已保存: {scatter_path}")

    # 图2.5: swivel_error vs elbow_error 散点图 (新增!)
    fig, ax = plt.subplots(figsize=(10, 8))

    scatter = ax.scatter(swivel_errors, elbow_errors, alpha=0.3, s=10, c=frame_indices, cmap='viridis')
    ax.set_xlabel('Swivel Error (°)')
    ax.set_ylabel('Elbow Error (mm)')
    ax.set_title(f'Swivel vs Elbow Error Correlation ({model_name})\nr = {swivel_elbow_corr:.3f}')

    # 添加回归线
    from scipy.stats import linregress
    slope, intercept, r_value, p_value, std_err = linregress(swivel_errors, elbow_errors)
    x_line = np.linspace(swivel_errors.min(), swivel_errors.max(), 100)
    y_line = slope * x_line + intercept
    ax.plot(x_line, y_line, 'r-', linewidth=2, label=f'y = {slope:.3f}x + {intercept:.3f}\nr = {r_value:.3f}')

    # 添加颜色条
    cbar = plt.colorbar(scatter, ax=ax)
    cbar.set_label('Frame Index')

    ax.legend()
    ax.grid(True, alpha=0.3)
    scatter_path2 = output_dir / f'swivel_elbow_scatter_{model_name}.png'
    plt.savefig(scatter_path2, dpi=150)
    plt.close()
    print(f"[Correlation] Swivel-Elbow散点图已保存: {scatter_path2}")

    # 图3: 滞后相关性图
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.bar(range(len(lag_correlations)), lag_correlations, color='steelblue', alpha=0.7)
    ax.axhline(y=correlation, color='r', linestyle='--', label=f'Simultaneous correlation: {correlation:.3f}')
    ax.set_xlabel('Lag (frames)')
    ax.set_ylabel('Correlation')
    ax.set_title(f'Lag Correlation ({model_name})')
    ax.legend()
    ax.grid(True, alpha=0.3)
    lag_path = output_dir / f'lag_correlation_{model_name}.png'
    plt.savefig(lag_path, dpi=150)
    plt.close()
    print(f"[Correlation] 滞后相关图已保存: {lag_path}")

    # 5. 保存原始数据
    data_path = output_dir / f'error_timeseries_{model_name}.npz'
    np.savez_compressed(
        data_path,
        frame_indices=frame_indices,
        swivel_errors=swivel_errors,
        elbow_errors=elbow_errors,
        joint_errors=joint_errors,
        correlation=correlation,
        swivel_elbow_corr=swivel_elbow_corr,
        elbow_joint_corr=elbow_joint_corr,
        peak_sync_ratio=peak_sync_ratio,
        lag_correlations=np.array(lag_correlations)
    )
    print(f"[Correlation] 原始数据已保存: {data_path}")

    # 6. 诊断结论
    print(f"\n[Correlation] === 诊断结果 ===")
    print(f"[Correlation] Pearson 相关系数: r = {correlation:.3f} (p < {p_value:.3e})")

    if correlation > 0.7:
        diagnosis = "高相关 - 臂角预测误差是导致关节角度误差的主要原因"
        solution = "建议优化模型预测精度"
    elif correlation < 0.3:
        diagnosis = "低相关 - IK 求解器可能存在问题"
        solution = "建议检查 IK 求解器配置"
    else:
        diagnosis = "中等相关 - 可能是混合因素"
        solution = "建议同时优化模型和 IK 求解器"

    print(f"[Correlation] 峰值同步率: {peak_sync_ratio*100:.1f}%")
    print(f"[Correlation] 诊断: {diagnosis}")
    print(f"[Correlation] 建议: {solution}")

    statistics = {
        'correlation': float(correlation),
        'swivel_elbow_correlation': float(swivel_elbow_corr),
        'elbow_joint_correlation': float(elbow_joint_corr),
        'p_value': float(p_value),
        'peak_sync_ratio': float(peak_sync_ratio),
        'max_lag_correlation': float(max(lag_correlations)) if lag_correlations else 0.0,
        'swivel_error_mean': float(swivel_errors.mean()),
        'swivel_error_std': float(swivel_errors.std()),
        'elbow_error_mean': float(elbow_errors.mean()),
        'elbow_error_std': float(elbow_errors.std()),
        'joint_error_mean': float(joint_errors.mean()),
        'joint_error_std': float(joint_errors.std()),
        'elbow_diagnosis': elbow_diagnosis,
        'diagnosis': diagnosis,
        'solution': solution
    }

    return statistics


# ============================================================================
# 传统 IK 求解器 - 用于初始化保证解的一致性
# ============================================================================

class TraditionalIKSolver:
    """
    传统 IK 求解器 - 基于优化的方法

    用途:
    - 为 HierarchicalIKSolver 提供一致的初始值
    - 解决 IK 多解问题（收敛到最接近 q_init 的解）

    与 HierarchicalIKSolver 的区别:
    - HierarchicalIKSolver: 分层求解（先末端，再肘部）→ 零空间多解
    - TraditionalIKSolver: 直接优化 → 唯一解（最接近初值）
    """

    def __init__(self, model, ee_frame_name='L_ee', ee_offset=0.05):
        """
        Args:
            model: Pinocchio 机器人模型
            ee_frame_name: 末端执行器帧名称
            ee_offset: 末端执行器偏移量（米）
        """
        self.model = model
        self.ee_frame_name = ee_frame_name
        self.ee_offset = ee_offset
        self.pin = __import__('pinocchio')

        # 获取末端帧的父关节
        try:
            self.ee_frame_id = self.model.getFrameId(ee_frame_name)
            self.ee_joint_id = self.model.frames[self.ee_frame_id].parent
        except:
            # 如果帧不存在，使用最后一个关节
            self.ee_frame_id = None
            # Pinocchio 3.x: 使用 model.nq 作为配置空间维度
            # 注意：nq 可能大于关节数（连续关节有多个维度），这里简化处理
            try:
                self.ee_joint_id = self.model.nq - 1
            except:
                # 如果还是失败，使用一个合理的默认值
                self.ee_joint_id = 6  # 7 DOF 机械臂的最后一个关节索引

    def forward_kinematics(self, q):
        """计算末端执行器位姿"""
        # Pinocchio 3.x: 使用 model 而不是 RobotWrapper
        self.pin.framesForwardKinematics(self.model.model, self.model.data, q)

        # 获取末端执行器位姿
        if self.ee_frame_id is not None:
            T_ee = self.model.data.oMf[self.ee_frame_id].copy()
        else:
            # 如果帧不存在，返回单位位姿
            T_ee = self.pin.SE3.Identity()

        # 添加末端偏移（直接修改 translation）
        if self.ee_offset > 0:
            # 将偏移应用到当前位姿的旋转坐标系中
            offset_local = np.array([self.ee_offset, 0, 0])
            offset_world = T_ee.rotation @ offset_local
            T_ee.translation = T_ee.translation + offset_world

        return T_ee

    def compute_error(self, q, T_target):
        """
        计算当前位姿与目标位姿的误差

        Returns:
            error: 6D 误差向量 [位置误差(3), 旋转误差(3)]
        """
        T_current = self.forward_kinematics(q)

        # 位置误差
        pos_error = T_target.translation - T_current.translation

        # 旋转误差（使用 SO(3) log 映射）
        R_error = T_target.rotation.T @ T_current.rotation
        rot_error = self.pin.log3(R_error)

        return np.concatenate([pos_error, rot_error])

    def solve(self, T_target, q_init=None, max_iter=100, verbose=False):
        """
        求解 IK

        Args:
            T_target: 目标位姿 (SE(3) 变换矩阵或 4x4 numpy 数组)
            q_init: 初始关节角度
            max_iter: 最大迭代次数
            verbose: 是否打印调试信息

        Returns:
            q_solved: 求解的关节角度
            info: 信息字典 {'converged': bool, 'error': float}
        """
        if q_init is None:
            q_init = self.pin.neutral(self.model)

        # 转换 T_target 为 pinocchio.SE3
        if isinstance(T_target, np.ndarray) and T_target.shape == (4, 4):
            T_target_se3 = self.pin.SE3(T_target[:3, :3], T_target[:3, 3])
        else:
            T_target_se3 = T_target

        # 目标函数：最小化位姿误差 + 与初值的距离
        def objective(q):
            pose_error = self.compute_error(q, T_target_se3)
            # 位姿误差权重更高，确保主要约束满足
            return 1000 * np.sum(pose_error**2) + 0.1 * np.sum((q - q_init)**2)

        # 约束：关节限位（-π 到 π）
        bounds = [(-np.pi, np.pi)] * self.model.nq

        # 使用 SLSQP 方法求解
        result = minimize(
            objective,
            q_init,
            method='SLSQP',
            bounds=bounds,
            options={'maxiter': max_iter, 'ftol': 1e-6, 'disp': verbose}
        )

        # 计算最终误差
        final_error = np.linalg.norm(self.compute_error(result.x, T_target_se3))

        if verbose:
            print(f"[TraditionalIK] Converged: {result.success}, Error: {final_error:.6f}")

        return result.x, {'converged': result.success, 'error': final_error}


def compute_joint_mae(
    pred_swivel: np.ndarray,
    gt_swivel: np.ndarray,
    gt_joints: np.ndarray,
    T_ee: np.ndarray,
    p_s: np.ndarray,
    p_w: np.ndarray,
    L_upper: np.ndarray,
    L_lower: np.ndarray,
    is_valid: np.ndarray = None,
    use_ik_solver: bool = False,
    ik_solver=None,
    traditional_ik=None
) -> float:
    """
    Metric 5: Joint MAE (端到端关节角度误差, 单位: Degree)

    物理意义：评估"网络意图 + 分层 IK 求解器"在真实七自由度机器人上的最终表现

    代码要求：
    - 将网络输出送入 HierarchicalIKSolver 解算得到 q_pred
    - 与 Ground Truth 的 q 求 MAE

    注意：
    - 方法1 (use_ik_solver=False): 使用肘部位置误差估算关节角度误差
    - 方法2 (use_ik_solver=True): 调用真实的 IK 求解器（较慢但更精确）

    修复 (2026-03-01):
    - 使用正确的 GT swivel (gt_swivel) 而不是错误的 np.mean(gt_joints)
    - 使用更精确的经验系数 (1/3 而不是 1/4)
    - 添加真实 IK 求解器支持
    - 添加传统 IK 初始化，解决多解问题
    """
    if gt_joints is None:
        return -1.0  # 无法计算

    if use_ik_solver and ik_solver is not None:
        return compute_joint_mae_with_ik(
            pred_swivel, gt_swivel, gt_joints, T_ee,
            p_s, p_w, L_upper, L_lower, is_valid, ik_solver,
            traditional_ik=traditional_ik
        )

    # 简化方法：使用肘部位置误差估算关节角度误差
    # 经验公式：肘部位置误差 (mm) / 3 ≈ 关节角度误差 (度)
    # 这是因为肘关节对臂角最敏感，1° 臂角误差 ≈ 3mm 肘部位置误差
    # 相关性分析验证: r = 0.78，说明肘部误差与关节误差高度相关
    target_gen = TargetGenerator()

    joint_errors = []
    for i in range(len(pred_swivel)):
        p_e_pred = target_gen.compute_target_elbow_position(
            pred_swivel[i], p_s[i], p_w[i], L_upper[i], L_lower[i]
        )
        # 修复：使用正确的 GT swivel (而不是错误的 np.mean(gt_joints))
        p_e_gt = target_gen.compute_target_elbow_position(
            gt_swivel[i],  # 使用正确的 GT swivel
            p_s[i], p_w[i], L_upper[i], L_lower[i]
        )
        # 肘部位置误差 (mm) / 3 ≈ 关节角度误差 (度)
        # 修复：使用 1/3 系数 (基于相关性分析)
        pos_error_mm = np.linalg.norm(p_e_pred - p_e_gt) * 1000
        joint_error_deg = pos_error_mm / 3.0  # 修正系数: 1/3
        joint_errors.append(joint_error_deg)

    joint_errors = np.array(joint_errors)

    if is_valid is not None:
        joint_errors = joint_errors[is_valid > 0.5]

    return joint_errors.mean()


def compute_joint_mae_with_ik(
    pred_swivel: np.ndarray,
    gt_swivel: np.ndarray,
    gt_joints: np.ndarray,
    T_ee: np.ndarray,
    p_s: np.ndarray,
    p_w: np.ndarray,
    L_upper: np.ndarray,
    L_lower: np.ndarray,
    is_valid: np.ndarray,
    ik_solver,
    traditional_ik=None
) -> float:
    """
    使用真实 IK 求解器计算关节角度 MAE

    流程:
    1. 从预测 swivel 获取肘部位置 (TargetGenerator)
    2. 使用传统 IK 初始化（保证解的一致性）
    3. 使用 HierarchicalIKSolver 求解关节角度
    4. 与 GT 关节角度比较

    参数:
        traditional_ik: 传统 IK 求解器，用于初始化保证解的一致性
    """
    if not REAL_IK_AVAILABLE:
        print("[Warning] 真实 IK 不可用，使用近似方法")
        return compute_joint_mae(
            pred_swivel, gt_swivel, gt_joints, T_ee,
            p_s, p_w, L_upper, L_lower, is_valid,
            use_ik_solver=False, ik_solver=None
        )

    target_gen = TargetGenerator()
    joint_errors = []
    converged_count = 0
    total_count = 0

    use_traditional_init = traditional_ik is not None and SCIPY_AVAILABLE
    init_method = "传统 IK 初始化" if use_traditional_init else "GT 初始化"
    print(f"[IK] 使用真实 IK 求解器计算 Joint MAE ({len(pred_swivel)} 帧, {init_method})...")

    for i in range(len(pred_swivel)):
        # 1. 从预测 swivel 获取肘部位置
        p_e_pred = target_gen.compute_target_elbow_position(
            pred_swivel[i], p_s[i], p_w[i], L_upper[i], L_lower[i]
        )

        # 2. 准备初始关节角度
        q_init_full = np.zeros(14, dtype=np.float32)

        if use_traditional_init and gt_joints is not None:
            # 使用传统 IK 初始化：先求解末端位姿，保证解的一致性
            # 扩展为 14 个关节（左臂 7 + 右臂 7）
            q_init_14d = np.zeros(14, dtype=np.float32)
            q_init_14d[:7] = gt_joints[i]
            # 右臂使用 0（中性位置）

            q_traditional, trad_info = traditional_ik.solve(
                T_target=T_ee[i],
                q_init=q_init_14d,  # 用 14 维的初值
                max_iter=50,
                verbose=False
            )
            q_init_full[:7] = q_traditional[:7]
        elif gt_joints is not None:
            # 直接使用 GT 作为初值（可能导致多解问题）
            q_init_full[:7] = gt_joints[i]

        # 3. 使用 HierarchicalIKSolver 求解（满足肘部位置约束）
        q_solved, info = ik_solver.solve(
            T_ee_target=T_ee[i],
            p_e_target=p_e_pred,
            q_init=q_init_full,
            max_iter=50,
            verbose=False
        )

        # 4. 计算与 GT 的误差 (度) - 只比较左臂 7 个关节
        q_solved_left_arm = q_solved[:7]
        error = np.degrees(np.abs(q_solved_left_arm - gt_joints[i])).mean()
        joint_errors.append(error)

        total_count += 1
        if info.get('converged', False):
            converged_count += 1

        # 进度打印
        if (i + 1) % 10000 == 0:
            print(f"  已处理: {i + 1:,}/{len(pred_swivel):,}")

    joint_errors = np.array(joint_errors)

    if is_valid is not None:
        joint_errors = joint_errors[is_valid > 0.5]

    print(f"[IK] 收敛率: {converged_count}/{total_count} ({100*converged_count/total_count:.1f}%)")
    print(f"[IK] Joint MAE: {joint_errors.mean():.2f}°")

    return joint_errors.mean()


# ============================================================================
# 主函数
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description='PiM-IK 综合评估 (遵循全局评估标准)')
    parser.add_argument('--data_path', type=str,
                        default='/data0/wwb_data/ygx_data/data_ygx_pose+dof/ACCAD_CMU_merged_training_data_with_swivel.npz',
                        help='数据集路径')
    parser.add_argument('--checkpoint_dir', type=str,
                        default='/home/ygx/ygx_hl_ik_v2/checkpoints',
                        help='检查点目录')
    parser.add_argument('--experiment', type=str, required=True,
                        choices=['loss_ablation', 'window_size_ablation', 'backbone_ablation', 'layers_ablation'],
                        help='实验类型')
    parser.add_argument('--num_frames', type=int, default=None,
                        help='评估帧数 (None=全部验证集)')
    parser.add_argument('--device', type=str, default='cuda:0',
                        help='计算设备')
    parser.add_argument('--output', type=str,
                        default=None,  # 默认根据实验类型自动生成
                        help='结果输出路径 (默认: evaluation_results_{experiment}.json)')
    parser.add_argument('--no_latency', action='store_true',
                        help='跳过延迟测试（加快评估）')
    parser.add_argument('--use-real-ik', action='store_true',
                        help='使用真实 IK 求解器计算 Joint MAE (较慢但更精确)')
    parser.add_argument('--analyze-correlation', action='store_true',
                        help='分析臂角误差与关节角度误差的时间序列关联性')
    parser.add_argument('--sample-ratio', type=float, default=0.1,
                        help='关联分析采样比例 (默认: 0.1 = 10%%)')

    args = parser.parse_args()

    # 自动生成输出文件名 (新格式: evaluation/{experiment}/{dataset}_{ik_type}_{timestamp}.json)
    if args.output is None:
        # 从数据路径提取数据集名称
        dataset_name = Path(args.data_path).stem.replace('_training_data_with_swivel', '')
        ik_type = 'real-ik' if args.use_real_ik else 'approx'
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        # 按实验类型分类保存到子目录
        args.output = f'/home/ygx/ygx_hl_ik_v2/evaluation/{args.experiment}/{dataset_name}_{ik_type}_{timestamp}.json'

    print("=" * 120)
    print("PiM-IK 综合评估 (遵循全局评估标准)")
    print("=" * 120)

    device = args.device if torch.cuda.is_available() else 'cpu'
    print(f"\n[Device] {device}")
    print(f"[Experiment] {args.experiment}")
    print(f"[Output] {args.output}")

    # 初始化真实 IK 求解器（如果需要）
    ik_solver = None
    traditional_ik = None  # 传统 IK 求解器，用于初始化保证解的一致性

    if args.use_real_ik:
        if REAL_IK_AVAILABLE:
            print("[IK] 初始化真实 IK 求解器...")
            try:
                # 尝试直接从缓存文件加载，避免 Pinocchio 3.x API 兼容性问题
                cache_path = '/home/ygx/hl_ik_xr_tele/teleop/robot_control/g1_29_model_cache.pkl'

                if os.path.exists(cache_path):
                    print(f"[IK] 从缓存文件加载模型: {cache_path}")
                    import pickle
                    import pinocchio as pin

                    with open(cache_path, 'rb') as f:
                        cache_data = pickle.load(f)

                    # 从缓存获取完整的机器人模型
                    robot = pin.RobotWrapper()
                    robot.model = cache_data["robot_model"]
                    robot.data = robot.model.createData()

                    # 创建左臂简化模型
                    joints_to_lock = [
                        "right_hip_yaw_joint", "right_hip_roll_joint", "right_hip_pitch_joint",
                        "right_knee_joint", "right_ankle_pitch_joint", "right_ankle_roll_joint",
                        "left_hip_yaw_joint", "left_hip_roll_joint", "left_hip_pitch_joint",
                        "left_knee_joint", "left_ankle_pitch_joint", "left_ankle_roll_joint",
                        "torso_joint", "left_shoulder_pitch_joint",
                        "right_shoulder_pitch_joint", "right_shoulder_roll_joint",
                        "right_shoulder_yaw_joint", "right_elbow_joint",
                        "right_wrist_yaw_joint", "right_wrist_pitch_joint", "right_wrist_roll_joint",
                        "left_hand_thumb_0_joint", "left_hand_thumb_1_joint", "left_hand_thumb_2_joint",
                        "left_hand_middle_0_joint", "left_hand_middle_1_joint",
                        "left_hand_index_0_joint", "left_hand_index_1_joint",
                        "right_hand_thumb_0_joint", "right_hand_thumb_1_joint", "right_hand_thumb_2_joint",
                        "right_hand_index_0_joint", "right_hand_index_1_joint",
                        "right_hand_middle_0_joint", "right_hand_middle_1_joint"
                    ]

                    # 使用 Pinocchio 3.x API 构建 reduced model
                    try:
                        # Pinocchio 3.x 新 API
                        left_arm_robot = robot.buildReducedRobot(
                            list_of_joints_to_lock=joints_to_lock,
                            reference_configuration=pin.neutral(robot.model),
                        )
                    except Exception as e2:
                        # 如果 buildReducedRobot 失败，尝试手动构建
                        print(f"[IK] buildReducedRobot 失败: {e2}")
                        print(f"[IK] 尝试从缓存加载 reduced_model...")
                        if "reduced_model" in cache_data:
                            left_arm_robot = pin.RobotWrapper()
                            left_arm_robot.model = cache_data["reduced_model"]
                            left_arm_robot.data = left_arm_robot.model.createData()
                        else:
                            raise e2

                    # 确保有 L_ee 帧
                    try:
                        if 'L_ee' not in [f.name for f in left_arm_robot.model.frames]:
                            left_arm_robot.model.addFrame(
                                pin.Frame('L_ee',
                                          left_arm_robot.model.getJointId('left_wrist_yaw_joint'),
                                          pin.SE3(np.eye(3), np.array([0.05, 0, 0]).T),
                                          pin.FrameType.OP_FRAME)
                            )
                            left_arm_robot.data = left_arm_robot.model.createData()
                    except Exception:
                        pass  # 帧可能已存在

                    print(f"[IK] ✓ 模型加载成功 (nq={left_arm_robot.model.nq})")

                else:
                    # 回退到完整初始化
                    print(f"[IK] 缓存文件不存在，尝试完整初始化...")
                    arm_ik = G1_29_ArmIK(Unit_Test=True, Visualization=False)
                    left_arm_robot = arm_ik.left_arm_robot

                ik_solver = HierarchicalIKSolver(
                    model=left_arm_robot,
                    ee_frame_name='L_ee',
                    ee_offset=0.05
                )
                print("[IK] ✓ HierarchicalIKSolver 初始化成功")

                # 初始化传统 IK 求解器（用于初始化，保证解的一致性）
                traditional_ik = None
                if SCIPY_AVAILABLE:
                    try:
                        traditional_ik = TraditionalIKSolver(
                            model=left_arm_robot,
                            ee_frame_name='L_ee',
                            ee_offset=0.05
                        )
                        print("[IK] ✓ TraditionalIKSolver 初始化成功（用于一致性初始化）")
                    except Exception as e2:
                        print(f"[IK] TraditionalIKSolver 初始化失败: {e2}")
                        print("[IK] 将使用 GT 作为初值（可能有多解问题）")
                else:
                    print("[IK] scipy 不可用，将使用 GT 作为初值（可能有多解问题）")
            except Exception as e:
                print(f"[IK] ✗ IK 求解器初始化失败: {e}")
                import traceback
                traceback.print_exc()
                print("[IK] 将使用近似方法")
                args.use_real_ik = False
        else:
            print("[IK] 真实 IK 不可用，使用近似方法")
            args.use_real_ik = False

    # 加载数据
    data = load_validation_data(args.data_path, num_frames=args.num_frames)

    # 定义模型配置
    if args.experiment == 'loss_ablation':
        models = {
            'Baseline (swivel_only)': 'loss_ablation/01_swivel_only/best_model_w30_sw1.0_el0.0_sm0.0.pth',
            'Variant A (+elbow)': 'loss_ablation/02_swivel_elbow/best_model_w30_sw1.0_el1.0_sm0.0.pth',
            'Ours (full_loss)': 'loss_ablation/03_full_loss/best_model_w30_sw1.0_el1.0_sm0.1.pth',
        }
        window_size = 30
    elif args.experiment == 'window_size_ablation':
        models = {
            'W=1': 'window_size_ablation/W1_window_size1/best_model_w1.pth',
            'W=15': 'window_size_ablation/W15_window_size15/best_model_w15.pth',
            'W=30': 'window_size_ablation/W30_window_size30/best_model.pth',
        }
        window_size = None  # 从 checkpoint 读取
    elif args.experiment == 'backbone_ablation':
        models = {
            'LSTM': 'backbone_ablation/lstm/best_model_lstm_w30_sw1.0_el1.0_sm0.1.pth',
            'Mamba': 'backbone_ablation/mamba/best_model_mamba_w30_sw1.0_el1.0_sm0.1.pth',
            'Transformer': 'backbone_ablation/transformer/best_model_transformer_w30_sw1.0_el1.0_sm0.1.pth',
        }
        window_size = 30
    elif args.experiment == 'layers_ablation':
        models = {
            'L=2': 'layers_ablation/L2_layers2/best_model_mamba_L2_w30_sw1.0_el1.0_sm0.1.pth',
            'L=3': 'layers_ablation/L3_layers3/best_model_mamba_L3_w30_sw1.0_el1.0_sm0.1.pth',
            'L=4': 'layers_ablation/L4_layers4/best_model_mamba_L4_w30_sw1.0_el1.0_sm0.1.pth',
        }
        window_size = 30

    # 评估所有模型
    results = {}

    for name, rel_path in models.items():
        print(f"\n{'='*80}")
        print(f"[{name}]")
        print(f"{'='*80}")

        ckpt_path = os.path.join(args.checkpoint_dir, rel_path)

        if not os.path.exists(ckpt_path):
            print(f"[Warning] 模型不存在: {ckpt_path}")
            continue

        # 加载模型
        model, config = load_model(ckpt_path, device)

        # 确定窗口大小
        ws = config.get('window_size', window_size) if window_size is None else window_size

        # 统计参数量
        params_k = count_parameters(model) / 1000

        # 测量推理延迟
        if not args.no_latency:
            print(f"[Latency] 测量推理延迟...")
            latency = measure_inference_latency(model, data['T_ee'][0], ws, device)
            print(f"  Latency: {latency['mean']:.3f} ms (p95: {latency['p95']:.3f} ms)")
        else:
            latency = {'mean': -1, 'p95': -1}

        # 打印配置信息
        print(f"[Config] Window: {ws}, Epoch: {config.get('epoch', '?')}, Val Loss: {config.get('val_loss', '?'):.4f}")
        print(f"[Config] Params: {params_k:.1f} K")

        # 推理
        pred_swivel = run_inference(model, data['T_ee'], ws, device)

        # 对齐 GT（跳过 warmup）
        warmup = ws - 1
        gt_aligned = data['swivel'][warmup:]
        is_valid_aligned = data['is_valid'][warmup:]
        p_s_aligned = data['p_s'][warmup:]
        p_w_aligned = data['p_w'][warmup:]
        p_e_gt_aligned = data['p_e_gt'][warmup:]
        L_upper_aligned = data['L_upper'][warmup:]
        L_lower_aligned = data['L_lower'][warmup:]
        T_ee_aligned = data['T_ee'][warmup:]

        # GT 关节角度
        if data['gt_joints'] is not None:
            gt_joints_aligned = data['gt_joints'][warmup:]
        else:
            gt_joints_aligned = None

        # 计算核心指标
        print(f"[Metrics] 计算评估指标...")

        metrics = {
            'params_k': float(params_k),
            'latency_ms': float(latency['mean']),
            'latency_p95_ms': float(latency['p95']),
            'swivel_mae': float(compute_swivel_mae(pred_swivel, gt_aligned, is_valid_aligned)),
            'elbow_error_mm': float(compute_elbow_error(
                pred_swivel, gt_aligned, p_s_aligned, p_w_aligned,
                L_upper_aligned, L_lower_aligned, is_valid_aligned
            )),
            'jerk': float(compute_jerk(pred_swivel, is_valid_aligned)),
            'joint_mae': float(compute_joint_mae(
                pred_swivel, gt_aligned, gt_joints_aligned, T_ee_aligned,
                p_s_aligned, p_w_aligned, L_upper_aligned, L_lower_aligned,
                is_valid_aligned, use_ik_solver=args.use_real_ik, ik_solver=ik_solver,
                traditional_ik=traditional_ik
            )),
            'window_size': int(ws),
            'epoch': int(config.get('epoch', -1)),
            'val_loss': float(config.get('val_loss', -1)),
        }

        results[name] = metrics

        # 关联分析 (如果启用)
        if args.analyze_correlation and args.use_real_ik and ik_solver is not None:
            # 清理模型名称用于文件名
            model_name_clean = name.replace(' ', '_').replace('(', '').replace(')', '').replace('*', '')
            # 创建输出目录
            output_dir = Path(args.output).parent

            correlation_stats = analyze_error_correlation(
                pred_swivel=pred_swivel,
                gt_swivel=gt_aligned,
                gt_joints=gt_joints_aligned,
                T_ee=T_ee_aligned,
                p_s=p_s_aligned,
                p_w=p_w_aligned,
                L_upper=L_upper_aligned,
                L_lower=L_lower_aligned,
                is_valid=is_valid_aligned,
                ik_solver=ik_solver,
                traditional_ik=traditional_ik,
                output_dir=output_dir,
                model_name=model_name_clean,
                sample_ratio=args.sample_ratio
            )
            # 将关联分析结果添加到 metrics
            metrics['correlation_analysis'] = correlation_stats

        print(f"\n[Results] {name}:")
        print(f"  Params: {metrics['params_k']:.1f} K")
        print(f"  Latency: {metrics['latency_ms']:.3f} ms (p95: {metrics['latency_p95_ms']:.3f} ms)")
        print(f"  Swivel MAE: {metrics['swivel_mae']:.2f}°")
        print(f"  Elbow Error: {metrics['elbow_error_mm']:.2f} mm")
        print(f"  Jerk: {metrics['jerk']:.4f}")
        if metrics['joint_mae'] > 0:
            print(f"  Joint MAE: {metrics['joint_mae']:.2f}°")

    # 保存结果 (添加元数据)
    output_path = args.output

    # 提取数据集名称
    dataset_name = Path(args.data_path).stem.replace('_training_data_with_swivel', '')
    ik_type = 'real-ik' if args.use_real_ik else 'approx'

    # 构建带元数据的结果
    output_data = {
        '_metadata': {
            'experiment': args.experiment,
            'dataset': dataset_name,
            'dataset_path': args.data_path,
            'ik_type': ik_type,
            'timestamp': time.strftime("%Y-%m-%dT%H:%M:%S"),
            'num_frames': (len(data['T_ee']) - (window_size if 'window_size' in locals() and window_size is not None else 30) + 1) if 'pred_swivel' in locals() else len(data['T_ee']),
            'device': device,
        },
        'results': results
    }

    with open(output_path, 'w') as f:
        json.dump(output_data, f, indent=2)

    print(f"\n[Save] 结果已保存到: {output_path}")

    # ========================================================================
    # 标准化 Markdown 表格输出 (遵循全局评估标准)
    # ========================================================================
    print("\n" + "=" * 140)
    print("综合评估结果 (PiM-IK Evaluation Protocol)")
    print("=" * 140)

    if results:
        # 标准表格 (包含 Joint MAE)
        has_joint_mae = any(results[name].get('joint_mae', -1) > 0 for name in results)

        if has_joint_mae:
            print(f"\n| Model / Config | Params (K) | Latency (ms) | Swivel MAE (°) ↓ | Elbow Error (mm) ↓ | Jerk ↓ | Joint MAE (°) ↓ |")
            print("|" + "|".join(["-" * 18] * 7) + "|")
        else:
            print(f"\n| Model / Config | Params (K) | Latency (ms) | Swivel MAE (°) ↓ | Elbow Error (mm) ↓ | Jerk ↓ |")
            print("|" + "|".join(["-" * 18] * 6) + "|")

        for name in results.keys():
            m = results[name]
            # 加粗 Ours 行
            is_ours = 'Ours' in name or 'W=30' in name or ('Mamba' in name and 'L=4' in name)

            if has_joint_mae:
                joint_mae_str = f"{m['joint_mae']:.2f}" if m['joint_mae'] > 0 else "N/A"
                if is_ours:
                    print(f"| **{name}** | **{m['params_k']:.1f}** | **{m['latency_ms']:.3f}** | **{m['swivel_mae']:.2f}** | **{m['elbow_error_mm']:.2f}** | **{m['jerk']:.4f}** | **{joint_mae_str}** |")
                else:
                    print(f"| {name} | {m['params_k']:.1f} | {m['latency_ms']:.3f} | {m['swivel_mae']:.2f} | {m['elbow_error_mm']:.2f} | {m['jerk']:.4f} | {joint_mae_str} |")
            else:
                if is_ours:
                    print(f"| **{name}** | **{m['params_k']:.1f}** | **{m['latency_ms']:.3f}** | **{m['swivel_mae']:.2f}** | **{m['elbow_error_mm']:.2f}** | **{m['jerk']:.4f}** |")
                else:
                    print(f"| {name} | {m['params_k']:.1f} | {m['latency_ms']:.3f} | {m['swivel_mae']:.2f} | {m['elbow_error_mm']:.2f} | {m['jerk']:.4f} |")

        print("\n**Legend**: ↓ indicates lower is better")
        print("**Note**: Latency measured on single forward pass with warmup")
        if args.use_real_ik:
            print("**Note**: Joint MAE computed using real IK solver")
        else:
            print("**Note**: Joint MAE uses approximate method (elbow error / 3)")

    print("=" * 140)


if __name__ == '__main__':
    main()
